# -*- coding: utf-8 -*-
"""step3_federated_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R9AyfCSn_sOhkgEqXAD3b-d2kRuHFyDM
"""

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from torch.utils.data import DataLoader, TensorDataset
from copy import deepcopy

# -------------------------------------------------
# SAME MODEL AS STEP 2 (DO NOT CHANGE)
# -------------------------------------------------
class GlobalCNN_Autoencoder(nn.Module):
    def __init__(self, input_features):
        super().__init__()

        self.encoder = nn.Sequential(
            nn.Conv1d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),

            nn.Conv1d(32, 16, kernel_size=3, padding=1),
            nn.BatchNorm1d(16),
            nn.ReLU(),

            nn.MaxPool1d(2)
        )

        self.decoder = nn.Sequential(
            nn.Upsample(scale_factor=2),

            nn.Conv1d(16, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(),

            nn.Conv1d(32, 1, kernel_size=3, padding=1)
        )

    def forward(self, x):
        return self.decoder(self.encoder(x))


# -------------------------------------------------
# LOAD BENIGN DATA ONLY
# -------------------------------------------------
def load_benign(csv_path, max_samples=100000):
    df = pd.read_csv(csv_path, nrows=max_samples)

    df = df.select_dtypes(include=[np.number])
    df = df.replace([np.inf, -np.inf], np.nan)
    df = df.dropna()

    scaler = StandardScaler()
    X = scaler.fit_transform(df.values)

    return X


# -------------------------------------------------
# LOCAL TRAINING (CLIENT SIDE)
# -------------------------------------------------
def train_local(model, data, epochs=5, batch_size=128):
    model.train()
    loader = DataLoader(
        TensorDataset(torch.tensor(data, dtype=torch.float32).unsqueeze(1)),
        batch_size=batch_size,
        shuffle=True
    )

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    loss_fn = nn.MSELoss()

    for _ in range(epochs):
        for (x,) in loader:
            optimizer.zero_grad()
            loss = loss_fn(model(x), x)
            loss.backward()
            optimizer.step()

    return deepcopy(model.state_dict())


# -------------------------------------------------
# FEDMEDIAN AGGREGATION
# -------------------------------------------------
def fed_median(weights):
    new_weights = {}
    for key in weights[0]:
        stacked = torch.stack([w[key] for w in weights])
        new_weights[key] = torch.median(stacked, dim=0).values
    return new_weights


# -------------------------------------------------
# MAIN FEDERATED LOOP
# -------------------------------------------------
if __name__ == "__main__":

    CLIENTS = {
        "A": "/content/Monday-WorkingHours.pcap_ISCX.csv",
        "B": "/content/Tuesday-WorkingHours.pcap_ISCX.csv",
        "C": "/content/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv"
    }

    ROUNDS = 5
    LOCAL_EPOCHS = 3

    # Load one dataset to get feature size
    sample_data = load_benign(list(CLIENTS.values())[0])
    input_features = sample_data.shape[1]

    # Load pretrained global model
    global_model = GlobalCNN_Autoencoder(input_features)
    global_model.load_state_dict(
        torch.load("/content/global_cnn_autoencoder.pt", map_location="cpu")
    )

    print("\nüîÅ Starting Federated Learning")

    for r in range(ROUNDS):
        print(f"\nRound {r+1}/{ROUNDS}")
        local_weights = []

        for cid, path in CLIENTS.items():
            print(f"  Training client {cid}")
            client_data = load_benign(path)

            local_model = deepcopy(global_model)
            weights = train_local(local_model, client_data, epochs=LOCAL_EPOCHS)
            local_weights.append(weights)

        # Aggregate
        global_weights = fed_median(local_weights)
        global_model.load_state_dict(global_weights)

        print("  üåê Global model updated")

    # Save final federated model
    torch.save(
        global_model.state_dict(),
        "global_federated_model.pt"
    )

    print("\n‚úÖ Federated global model saved")